{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24aa75fa-84be-43ba-9cac-3129f34fc597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install super-gradients\n",
    "#%pip install torch\n",
    "#%pip install supervision\n",
    "#%pip install roboflow\n",
    "#%pip install --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2eac127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics<=8.0.20 is required but found version=8.0.168, to fix: `pip install ultralytics<=8.0.20`\n",
      "Downloading Dataset Version Zip in YOLO-2 to yolov8: 100% [7621104 / 7621104] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to YOLO-2 in yolov8:: 100%|██████████| 612/612 [00:00<00:00, 1403.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"NNsjGsIb23GWj3zGDggC\")\n",
    "project = rf.workspace(\"yolo-hz3ua\").project(\"yolo-fj4s3\")\n",
    "dataset = project.version(2).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f7a1c2-1197-46df-b261-bb559cbcabde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-06 14:50:17] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is logged into C:\\Users\\mateu\\sg_logs\\console.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-06 14:50:18] WARNING - __init__.py - Failed to import pytorch_quantization\n",
      "[2023-09-06 14:50:19] WARNING - redirects.py - NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "[2023-09-06 14:50:22] WARNING - calibrator.py - Failed to import pytorch_quantization\n",
      "[2023-09-06 14:50:22] WARNING - export.py - Failed to import pytorch_quantization\n",
      "[2023-09-06 14:50:22] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n",
      "[2023-09-06 14:50:22] WARNING - env_sanity_check.py - \u001b[31mFailed to verify operating system: Deci officially supports only Linux kernels. Some features may not work as expected.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from super_gradients.training import Trainer\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ARCH = 'yolo_nas_l'\n",
    "ATCH_SIZE = 8\n",
    "MAX_EPOCHS = 15\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "EXPERIMENT_NAME = project.name.lower().replace(\" \", \"_\")\n",
    "\n",
    "from super_gradients.training import Trainer\n",
    "\n",
    "trainer = Trainer(experiment_name=EXPERIMENT_NAME, ckpt_root_dir=CHECKPOINT_DIR)\n",
    "\n",
    "LOCATION = dataset.location\n",
    "CLASSES = sorted(project.classes.keys())\n",
    "\n",
    "dataset_params = {\n",
    "    'data_dir': LOCATION,\n",
    "    'train_images_dir':'train/images',\n",
    "    'train_labels_dir':'train/labels',\n",
    "    'val_images_dir':'valid/images',\n",
    "    'val_labels_dir':'valid/labels',\n",
    "    'test_images_dir':'test/images',\n",
    "    'test_labels_dir':'test/labels',\n",
    "    'classes': CLASSES\n",
    "}\n",
    "print(dataset_params['classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d53441f-661c-4f36-90a5-bd28609d525c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-06 14:50:23] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tumor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing dataset annotations: 100%|██████████| 210/210 [00:01<00:00, 150.94it/s]\n",
      "[2023-09-06 14:50:24] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
      "Indexing dataset annotations:  73%|███████▎  | 44/60 [00:00<00:00, 133.69it/s]"
     ]
    }
   ],
   "source": [
    "from super_gradients.training.dataloaders.dataloaders import (coco_detection_yolo_format_train, coco_detection_yolo_format_val)\n",
    "\n",
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': 8,\n",
    "        'num_workers': 1\n",
    "    }\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': 8,\n",
    "        'num_workers': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79a89ec-78ea-4949-8194-d32ddf814c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing dataset annotations: 100%|██████████| 60/60 [00:00<00:00, 140.81it/s]\n",
      "[2023-09-06 14:50:25] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
      "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
      "By downloading the pre-trained weight files you agree to comply with these terms.\n",
      "[2023-09-06 14:50:26] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n"
     ]
    }
   ],
   "source": [
    "from super_gradients.training import models\n",
    "\n",
    "model = models.get(\n",
    "    MODEL_ARCH, \n",
    "    num_classes=len(dataset_params['classes']), \n",
    "    pretrained_weights=\"coco\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae17eabd-e9e2-490e-ab73-cc1a8637a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "\n",
    "train_params = {\n",
    "    'silent_mode': False,\n",
    "    \"average_best_models\":True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": MAX_EPOCHS,\n",
    "    \"mixed_precision\": True,\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b3f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "The console stream is now moved to ./checkpoints\\yolo/console_set06_14_50_26.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-06 14:50:30] INFO - sg_trainer.py - Using EMA with params {'decay': 0.9, 'decay_type': 'threshold'}\n",
      "[2023-09-06 14:50:40] INFO - sg_trainer_utils.py - TRAINING PARAMETERS:\n",
      "    - Mode:                         Single GPU\n",
      "    - Number of GPUs:               1          (1 available on the machine)\n",
      "    - Dataset size:                 210        (len(train_set))\n",
      "    - Batch size per GPU:           8          (batch_size)\n",
      "    - Batch Accumulate:             1          (batch_accumulate)\n",
      "    - Total batch size:             8          (num_gpus * batch_size)\n",
      "    - Effective Batch size:         8          (num_gpus * batch_size * batch_accumulate)\n",
      "    - Iterations per epoch:         26         (len(train_loader))\n",
      "    - Gradient updates per epoch:   26         (len(train_loader) / batch_accumulate)\n",
      "\n",
      "[2023-09-06 14:50:40] INFO - sg_trainer.py - Started training for 15 epochs (0/14)\n",
      "\n",
      "Train epoch 0:  27%|██▋       | 7/26 [03:09<08:34, 27.09s/it, PPYoloELoss/loss=3.93, PPYoloELoss/loss_cls=2.26, PPYoloELoss/loss_dfl=1.79, PPYoloELoss/loss_iou=0.312, gpu_mem=2.07]\n",
      "[2023-09-06 14:53:49] INFO - base_sg_logger.py - [CLEANUP] - Successfully stopped system monitoring process\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 3.00 GiB total capacity; 5.21 GiB already allocated; 0 bytes free; 5.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(DEVICE)\n\u001b[1;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m      3\u001b[0m     model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m      4\u001b[0m     training_params\u001b[39m=\u001b[39;49mtrain_params, \n\u001b[0;32m      5\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_data, \n\u001b[0;32m      6\u001b[0m     valid_loader\u001b[39m=\u001b[39;49mval_data\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\sg_trainer\\sg_trainer.py:1362\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, model, training_params, train_loader, valid_loader, test_loaders, additional_configs_to_log)\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1356\u001b[0m     device_config\u001b[39m.\u001b[39mmulti_gpu \u001b[39m==\u001b[39m MultiGPUMode\u001b[39m.\u001b[39mDISTRIBUTED_DATA_PARALLEL\n\u001b[0;32m   1357\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader, \u001b[39m\"\u001b[39m\u001b[39msampler\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1358\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader\u001b[39m.\u001b[39msampler, \u001b[39m\"\u001b[39m\u001b[39mset_epoch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1359\u001b[0m ):\n\u001b[0;32m   1360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader\u001b[39m.\u001b[39msampler\u001b[39m.\u001b[39mset_epoch(epoch)\n\u001b[1;32m-> 1362\u001b[0m train_metrics_tuple \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(context\u001b[39m=\u001b[39;49mcontext, silent_mode\u001b[39m=\u001b[39;49msilent_mode)\n\u001b[0;32m   1364\u001b[0m \u001b[39m# Phase.TRAIN_EPOCH_END\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m \u001b[39m# RUN PHASE CALLBACKS\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m train_metrics_dict \u001b[39m=\u001b[39m get_metrics_dict(train_metrics_tuple, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_metrics, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_logging_items_names)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\sg_trainer\\sg_trainer.py:439\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self, context, silent_mode)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39m# AUTOCAST IS ENABLED ONLY IF self.training_params.mixed_precision - IF enabled=False AUTOCAST HAS NO EFFECT\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mwith\u001b[39;00m autocast(enabled\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_params\u001b[39m.\u001b[39mmixed_precision):\n\u001b[0;32m    438\u001b[0m     \u001b[39m# FORWARD PASS TO GET NETWORK'S PREDICTIONS\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(inputs)\n\u001b[0;32m    441\u001b[0m     \u001b[39m# COMPUTE THE LOSS FOR BACK PROP + EXTRA METRICS COMPUTED DURING THE LOSS FORWARD PASS\u001b[39;00m\n\u001b[0;32m    442\u001b[0m     loss, loss_log_items \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_losses(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\models\\detection_models\\customizable_detector.py:89\u001b[0m, in \u001b[0;36mCustomizableDetector.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     88\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(x)\n\u001b[1;32m---> 89\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneck(x)\n\u001b[0;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads(x)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\models\\detection_models\\yolo_nas\\panneck.py:60\u001b[0m, in \u001b[0;36mYoloNASPANNeckWithC2.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     57\u001b[0m c2, c3, c4, c5 \u001b[39m=\u001b[39m inputs\n\u001b[0;32m     59\u001b[0m x_n1_inter, x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck1([c5, c4, c3])\n\u001b[1;32m---> 60\u001b[0m x_n2_inter, p3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneck2([x, c3, c2])\n\u001b[0;32m     61\u001b[0m p4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck3([p3, x_n2_inter])\n\u001b[0;32m     62\u001b[0m p5 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck4([p4, x_n1_inter])\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\models\\detection_models\\yolo_nas\\yolo_stages.py:314\u001b[0m, in \u001b[0;36mYoloNASUpStage.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    312\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, \u001b[39m*\u001b[39mskip_x], \u001b[39m1\u001b[39m)\n\u001b[0;32m    313\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduce_after_concat(x)\n\u001b[1;32m--> 314\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[0;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m x_inter, x\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\super_gradients\\training\\models\\detection_models\\yolo_nas\\yolo_stages.py:143\u001b[0m, in \u001b[0;36mYoloNASCSPLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m x_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottlenecks(x_1)\n\u001b[0;32m    142\u001b[0m x_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[1;32m--> 143\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((\u001b[39m*\u001b[39;49mx_1, x_2), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    144\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[0;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 3.00 GiB total capacity; 5.21 GiB already allocated; 0 bytes free; 5.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "print(DEVICE)\n",
    "trainer.train(\n",
    "    model=model, \n",
    "    training_params=train_params, \n",
    "    train_loader=train_data, \n",
    "    valid_loader=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU não disponível.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU disponível.\")\n",
    "    print(\"Dispositivo atual:\", torch.cuda.get_device_name(0))  # 0 é o índice da GPU, pode ser diferente\n",
    "    print(\"Memória VRAM disponível:\", torch.cuda.get_device_properties(0).total_memory / (1024 ** 2), \"MB\")\n",
    "else:\n",
    "    print(\"GPU não disponível.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
